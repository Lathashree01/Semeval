## NLP Project - Patronizing Language Classifier (SemEval 2022 Task 4 

Key Implementations:

1. Baseline Strategies:
 - Naive Bayes Classifier
 - Logistic Regression Classifier

2. RoBERTa-Based Model:
- Developed a RoBERTa-based model for text classification.

3. Top Performance:
- Achieved top 3rd place F1 score on the held-out test dataset.

4. Hyperparameter Tuning:
- Used the Optuna library for hyperparameter tuning.

The project showcases my ability to build and evaluate NLP models, from simple baselines to more advanced state-of-the-art approaches. 
Developed this as part of my Master's module - "Natural Language Processing" group project.

If you have any questions or feedback, please don't hesitate to reach out.

Few Important links:
Challenge website - https://competitions.codalab.org/competitions/34344 \
Link to github repo - https://github.com/Perez-AlmendrosC/dontpatronizeme
